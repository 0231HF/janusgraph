# input graph parameters
hadoop.graph.input.format=com.thinkaurelius.faunus.formats.titan.hbase.TitanHBaseInputFormat
hadoop.graph.input.titan.storage.backend=hbase
hadoop.graph.input.titan.storage.hostname=localhost
hadoop.graph.input.titan.storage.port=2181
hadoop.graph.input.titan.storage.tablename=titan
# hbase.mapreduce.scan.cachedrows=1000


hadoop.pipeline.track-state=true


# output data (graph or statistic) parameters
hadoop.graph.output.format=com.thinkaurelius.faunus.formats.titan.hbase.TitanHBaseOutputFormat
hadoop.graph.output.titan.storage.backend=hbase
hadoop.graph.output.titan.storage.hostname=localhost
hadoop.graph.output.titan.storage.port=2181
hadoop.graph.output.titan.storage.tablename=titan
hadoop.graph.output.titan.storage.batch-loading=true
# hadoop.graph.output.titan.ids.block-size=100000
# hadoop.graph.output.titan.storage.idauthority-wait-time=1000
hadoop.graph.output.titan.infer-schema=true
# hadoop.graph.output.blueprints.script-file=BlueprintsScript.groovy
# controls size of transaction
mapred.max.split.size=5242880
# mapred.reduce.tasks=10
mapred.job.reuse.jvm.num.tasks=-1

hadoop.sideeffect.output.format=org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
hadoop.output.location=output
hadoop.output.location.overwrite=true