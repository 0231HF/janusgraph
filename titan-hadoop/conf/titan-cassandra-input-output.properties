# input graph parameters
hadoop.graph.input.format=com.thinkaurelius.faunus.formats.titan.cassandra.TitanCassandraInputFormat
hadoop.graph.input.titan.storage.backend=cassandrathrift
hadoop.graph.input.titan.storage.hostname=localhost
hadoop.graph.input.titan.storage.port=9160
hadoop.graph.input.titan.storage.keyspace=titan
cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner
# cassandra.input.split.size=512
# cassandra.thrift.framed.size_mb=49
# cassandra.thrift.message.max_size_mb=50


hadoop.pipeline.track-state=true


# output data (graph or statistic) parameters
hadoop.graph.output.format=com.thinkaurelius.faunus.formats.titan.cassandra.TitanCassandraOutputFormat
hadoop.graph.output.titan.storage.backend=cassandrathrift
hadoop.graph.output.titan.storage.hostname=localhost
hadoop.graph.output.titan.storage.port=9160
hadoop.graph.output.titan.storage.keyspace=titan
hadoop.graph.output.titan.storage.batch-loading=true
# faunus.graph.output.titan.ids.block-size=100000
# faunus.graph.output.titan.storage.idauthority-wait-time=1000
# faunus.graph.output.titan.storage.cassandra.thrift.frame_size_mb=49
# faunus.graph.output.titan.storage.cassandra.thrift.max_message_size_mb=50
faunus.graph.output.titan.infer-schema=true
# faunus.graph.output.blueprints.script-file=BlueprintsScript.groovy
# controls size of transaction
mapred.max.split.size=5242880
# mapred.reduce.tasks=10
mapred.job.reuse.jvm.num.tasks=-1

hadoop.sideeffect.output.format=org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
hadoop.output.location=output
hadoop.output.location.overwrite=true

